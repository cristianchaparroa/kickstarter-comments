{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset \n",
    "\n",
    "1. Use the datasaet from https://www.kaggle.com/tayoaki/kickstarter-dataset#18k_Projects.csv\n",
    "2. Create a scraper from the above dataset an generate a new one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import scipy.stats as sp\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_url</th>\n",
       "      <th>comment</th>\n",
       "      <th>created_at</th>\n",
       "      <th>comment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.kickstarter.com/projects/200510190...</td>\n",
       "      <td>I am sorry for your personal problems however ...</td>\n",
       "      <td>1451947668</td>\n",
       "      <td>UHJvamVjdENvbW1lbnQtMTIxNzA1MDE=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.kickstarter.com/projects/200510190...</td>\n",
       "      <td>Ron, as I told you before, this book publishin...</td>\n",
       "      <td>1451760497</td>\n",
       "      <td>UHJvamVjdENvbW1lbnQtMTIxNjA2NjM=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.kickstarter.com/projects/200510190...</td>\n",
       "      <td>Ron, I really don't appreciate you calling me ...</td>\n",
       "      <td>1451759861</td>\n",
       "      <td>UHJvamVjdENvbW1lbnQtMTIxNjA2MzI=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.kickstarter.com/projects/200510190...</td>\n",
       "      <td>If anyone can help me find Dorian please conta...</td>\n",
       "      <td>1451712581</td>\n",
       "      <td>UHJvamVjdENvbW1lbnQtMTIxNTkwNjA=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.kickstarter.com/projects/200510190...</td>\n",
       "      <td>Dorian, I am going to track you down and expos...</td>\n",
       "      <td>1451712381</td>\n",
       "      <td>UHJvamVjdENvbW1lbnQtMTIxNTkwNDc=</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         project_url  \\\n",
       "0  https://www.kickstarter.com/projects/200510190...   \n",
       "1  https://www.kickstarter.com/projects/200510190...   \n",
       "2  https://www.kickstarter.com/projects/200510190...   \n",
       "3  https://www.kickstarter.com/projects/200510190...   \n",
       "4  https://www.kickstarter.com/projects/200510190...   \n",
       "\n",
       "                                             comment  created_at  \\\n",
       "0  I am sorry for your personal problems however ...  1451947668   \n",
       "1  Ron, as I told you before, this book publishin...  1451760497   \n",
       "2  Ron, I really don't appreciate you calling me ...  1451759861   \n",
       "3  If anyone can help me find Dorian please conta...  1451712581   \n",
       "4  Dorian, I am going to track you down and expos...  1451712381   \n",
       "\n",
       "                         comment_id  \n",
       "0  UHJvamVjdENvbW1lbnQtMTIxNzA1MDE=  \n",
       "1  UHJvamVjdENvbW1lbnQtMTIxNjA2NjM=  \n",
       "2  UHJvamVjdENvbW1lbnQtMTIxNjA2MzI=  \n",
       "3  UHJvamVjdENvbW1lbnQtMTIxNTkwNjA=  \n",
       "4  UHJvamVjdENvbW1lbnQtMTIxNTkwNDc=  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cms = pd.read_csv('./dataset/comments.csv')\n",
    "cms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a new column with the date accoriding with created_at field that is in milliseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.drop(['project_url'], 1,inplace=True)\n",
    "cms.drop(['comment_id'], 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am sorry for your personal problems however ...</td>\n",
       "      <td>1451947668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ron, as I told you before, this book publishin...</td>\n",
       "      <td>1451760497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ron, I really don't appreciate you calling me ...</td>\n",
       "      <td>1451759861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If anyone can help me find Dorian please conta...</td>\n",
       "      <td>1451712581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dorian, I am going to track you down and expos...</td>\n",
       "      <td>1451712381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  created_at\n",
       "0  I am sorry for your personal problems however ...  1451947668\n",
       "1  Ron, as I told you before, this book publishin...  1451760497\n",
       "2  Ron, I really don't appreciate you calling me ...  1451759861\n",
       "3  If anyone can help me find Dorian please conta...  1451712581\n",
       "4  Dorian, I am going to track you down and expos...  1451712381"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "# Load english tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se extrae el primer comentario del dataset y se procede a generar los tokens de este. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry for your personal problems however it is your responsible to keep your backers informed. an email once in a while would work.\n",
      "I would like to have your address, phone number and email address.\n",
      "by your actions and keeping your backers in the dark for a year and half I had no other choice but to feel that us backers had been scammed. I personally feel its been long enough already.\n",
      "so if this going to take another year? keep your backers in the loop. Taking our money and never hearing from you is a very asshole thing to do. welcome to the grown world.\n"
     ]
    }
   ],
   "source": [
    "# Word  tokenization, breaking up the text into individual words. \n",
    "\n",
    "text = cms['comment'][0]\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'sorry', 'for', 'your', 'personal', 'problems', 'however', 'it', 'is', 'your', 'responsible', 'to', 'keep', 'your', 'backers', 'informed', '.', 'an', 'email', 'once', 'in', 'a', 'while', 'would', 'work', '.', '\\n', 'I', 'would', 'like', 'to', 'have', 'your', 'address', ',', 'phone', 'number', 'and', 'email', 'address', '.', '\\n', 'by', 'your', 'actions', 'and', 'keeping', 'your', 'backers', 'in', 'the', 'dark', 'for', 'a', 'year', 'and', 'half', 'I', 'had', 'no', 'other', 'choice', 'but', 'to', 'feel', 'that', 'us', 'backers', 'had', 'been', 'scammed', '.', 'I', 'personally', 'feel', 'its', 'been', 'long', 'enough', 'already', '.', '\\n', 'so', 'if', 'this', 'going', 'to', 'take', 'another', 'year', '?', 'keep', 'your', 'backers', 'in', 'the', 'loop', '.', 'Taking', 'our', 'money', 'and', 'never', 'hearing', 'from', 'you', 'is', 'a', 'very', 'asshole', 'thing', 'to', 'do', '.', 'welcome', 'to', 'the', 'grown', 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "\n",
    "for token in doc:\n",
    "    tokens.append(token.text)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbd = nlp.create_pipe('sentencizer')\n",
    "# Add the component to the pipeline\n",
    "nlp.add_pipe(sbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "docst = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am sorry for your personal problems however it is your responsible to keep your backers informed.', 'an email once in a while would work.', '\\nI would like to have your address, phone number and email address.', '\\nby your actions and keeping your backers in the dark for a year and half I had no other choice but to feel that us backers had been scammed.', 'I personally feel its been long enough already.', '\\nso if this going to take another year?', 'keep your backers in the loop.', 'Taking our money and never hearing from you is a very asshole thing to do.', 'welcome to the grown world.']\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for s in docst.sents:\n",
    "    sentences.append(s.text)\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text data: Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words:326\n"
     ]
    }
   ],
   "source": [
    "print('Number of stop words:%d' % len(spacy_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First ten stop words: ['nowhere', 'whom', 'namely', 'side', 'amongst', '‘s', 'he', 'thence', 'otherwise', 'under', 'above', 'still', 'doing', 'these', 'me', 'anyhow', 'rather', 'their', 'thereafter', 'thereby']\n"
     ]
    }
   ],
   "source": [
    "print('First ten stop words: %s' % list(spacy_stopwords)[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se procede a emplear a limpiar las oraciones usando los stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered sentence: [sorry, personal, problems, responsible, backers, informed, ., email, work, ., \n",
      ", like, address, ,, phone, number, email, address, ., \n",
      ", actions, keeping, backers, dark, year, half, choice, feel, backers, scammed, ., personally, feel, long, ., \n",
      ", going, year, ?, backers, loop, ., Taking, money, hearing, asshole, thing, ., welcome, grown, world, .]\n"
     ]
    }
   ],
   "source": [
    "filtered_sentences = []\n",
    "for word in docst :\n",
    "    if word.is_stop == False:\n",
    "        filtered_sentences.append(word)\n",
    "print(\"Filtered sentence:\", filtered_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "Processing words that reduces them to their roots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I\n",
      "am be\n",
      "sorry sorry\n",
      "for for\n",
      "your your\n",
      "personal personal\n",
      "problems problem\n",
      "however however\n",
      "it it\n",
      "is be\n",
      "your your\n",
      "responsible responsible\n",
      "to to\n",
      "keep keep\n",
      "your your\n",
      "backers backer\n",
      "informed inform\n",
      ". .\n",
      "an a\n",
      "email email\n",
      "once once\n",
      "in in\n",
      "a a\n",
      "while while\n",
      "would would\n",
      "work work\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "I I\n",
      "would would\n",
      "like like\n",
      "to to\n",
      "have have\n",
      "your your\n",
      "address address\n",
      ", ,\n",
      "phone phone\n",
      "number numb\n",
      "and and\n",
      "email email\n",
      "address address\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "by by\n",
      "your your\n",
      "actions action\n",
      "and and\n",
      "keeping keep\n",
      "your your\n",
      "backers backer\n",
      "in in\n",
      "the the\n",
      "dark dark\n",
      "for for\n",
      "a a\n",
      "year year\n",
      "and and\n",
      "half half\n",
      "I I\n",
      "had have\n",
      "no no\n",
      "other other\n",
      "choice choice\n",
      "but but\n",
      "to to\n",
      "feel feel\n",
      "that that\n",
      "us us\n",
      "backers backer\n",
      "had have\n",
      "been be\n",
      "scammed scam\n",
      ". .\n",
      "I I\n",
      "personally personally\n",
      "feel feel\n",
      "its its\n",
      "been be\n",
      "long long\n",
      "enough enough\n",
      "already already\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "so so\n",
      "if if\n",
      "this this\n",
      "going go\n",
      "to to\n",
      "take take\n",
      "another another\n",
      "year year\n",
      "? ?\n",
      "keep keep\n",
      "your your\n",
      "backers backer\n",
      "in in\n",
      "the the\n",
      "loop loop\n",
      ". .\n",
      "Taking Taking\n",
      "our our\n",
      "money money\n",
      "and and\n",
      "never never\n",
      "hearing hear\n",
      "from from\n",
      "you you\n",
      "is be\n",
      "a a\n",
      "very very\n",
      "asshole asshole\n",
      "thing thing\n",
      "to to\n",
      "do do\n",
      ". .\n",
      "welcome welcome\n",
      "to to\n",
      "the the\n",
      "grown grow\n",
      "world world\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "lem = nlp(text)\n",
    "\n",
    "for word in lem:\n",
    "    print(word.text, word.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech (POS) Tagging\n",
    "\n",
    "Definir la funcion de una palabra dentro de una oración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the model en_core_web_sm of English for vocabluary, syntax & entities\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON\n",
      "am VERB\n",
      "sorry ADJ\n",
      "for ADP\n",
      "your DET\n",
      "personal ADJ\n",
      "problems NOUN\n",
      "however ADV\n",
      "it PRON\n",
      "is VERB\n",
      "your DET\n",
      "responsible ADJ\n",
      "to PART\n",
      "keep VERB\n",
      "your DET\n",
      "backers NOUN\n",
      "informed VERB\n",
      ". PUNCT\n",
      "an DET\n",
      "email NOUN\n",
      "once ADV\n",
      "in ADP\n",
      "a DET\n",
      "while NOUN\n",
      "would VERB\n",
      "work VERB\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "I PRON\n",
      "would VERB\n",
      "like VERB\n",
      "to PART\n",
      "have VERB\n",
      "your DET\n",
      "address NOUN\n",
      ", PUNCT\n",
      "phone NOUN\n",
      "number NOUN\n",
      "and CCONJ\n",
      "email NOUN\n",
      "address NOUN\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "by ADP\n",
      "your DET\n",
      "actions NOUN\n",
      "and CCONJ\n",
      "keeping VERB\n",
      "your DET\n",
      "backers NOUN\n",
      "in ADP\n",
      "the DET\n",
      "dark NOUN\n",
      "for ADP\n",
      "a DET\n",
      "year NOUN\n",
      "and CCONJ\n",
      "half NOUN\n",
      "I PRON\n",
      "had VERB\n",
      "no DET\n",
      "other ADJ\n",
      "choice NOUN\n",
      "but ADP\n",
      "to PART\n",
      "feel VERB\n",
      "that ADP\n",
      "us PRON\n",
      "backers NOUN\n",
      "had VERB\n",
      "been VERB\n",
      "scammed VERB\n",
      ". PUNCT\n",
      "I PRON\n",
      "personally ADV\n",
      "feel VERB\n",
      "its DET\n",
      "been VERB\n",
      "long ADV\n",
      "enough ADV\n",
      "already ADV\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "so ADV\n",
      "if ADP\n",
      "this DET\n",
      "going VERB\n",
      "to PART\n",
      "take VERB\n",
      "another DET\n",
      "year NOUN\n",
      "? PUNCT\n",
      "keep VERB\n",
      "your DET\n",
      "backers NOUN\n",
      "in ADP\n",
      "the DET\n",
      "loop NOUN\n",
      ". PUNCT\n",
      "Taking VERB\n",
      "our DET\n",
      "money NOUN\n",
      "and CCONJ\n",
      "never ADV\n",
      "hearing VERB\n",
      "from ADP\n",
      "you PRON\n",
      "is VERB\n",
      "a DET\n",
      "very ADV\n",
      "asshole ADJ\n",
      "thing NOUN\n",
      "to PART\n",
      "do VERB\n",
      ". PUNCT\n",
      "welcome VERB\n",
      "to ADP\n",
      "the DET\n",
      "grown ADJ\n",
      "world NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "pos = en_core_web_sm.load()\n",
    "\n",
    "pos_docs = pos(text)\n",
    "\n",
    "for word in pos_docs:\n",
    "    print(word.text, word.pos_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Detection\n",
    "\n",
    "Determinar a partir del texto lugares, personas, organizaciones...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry for your personal problems however it is your responsible to keep your backers informed. an email once in a while would work.\n",
      "I would like to have your address, phone number and email address.\n",
      "by your actions and keeping your backers in the dark for a year and half I had no other choice but to feel that us backers had been scammed. I personally feel its been long enough already.\n",
      "so if this going to take another year? keep your backers in the loop. Taking our money and never hearing from you is a very asshole thing to do. welcome to the grown world.\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "comment = pos(text)\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(a year, 'DATE', 391), (half, 'CARDINAL', 397), (another year, 'DATE', 391)]\n"
     ]
    }
   ],
   "source": [
    "entities=[(i, i.label_, i.label) for i in comment.ents]\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I am sorry for your personal problems however it is your responsible to keep your backers informed. an email once in a while would work.</br>I would like to have your address, phone number and email address.</br>by your actions and keeping your backers in the dark for \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    a year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    half\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " I had no other choice but to feel that us backers had been scammed. I personally feel its been long enough already.</br>so if this going to take \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    another year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "? keep your backers in the loop. Taking our money and never hearing from you is a very asshole thing to do. welcome to the grown world.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(comment, style = \"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Parsing \n",
    "\n",
    "Permite determinar el significado de la oración, analizando cómo esta construida la oración para determinar cómo las palabras individuales estan relaionadas unas a otras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I nsubj am\n",
      "your personal p p pobj for\n"
     ]
    }
   ],
   "source": [
    "docp = pos(text[:30])\n",
    "\n",
    "for chunk in docp.noun_chunks:\n",
    "   print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "          chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a2c2e019a3e54f6f814cc08513fcff9d-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">am</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">sorry</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">your</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">personal</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">p</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a2c2e019a3e54f6f814cc08513fcff9d-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a2c2e019a3e54f6f814cc08513fcff9d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a2c2e019a3e54f6f814cc08513fcff9d-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a2c2e019a3e54f6f814cc08513fcff9d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M390.0,266.5 L398.0,254.5 382.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a2c2e019a3e54f6f814cc08513fcff9d-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a2c2e019a3e54f6f814cc08513fcff9d-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a2c2e019a3e54f6f814cc08513fcff9d-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a2c2e019a3e54f6f814cc08513fcff9d-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a2c2e019a3e54f6f814cc08513fcff9d-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a2c2e019a3e54f6f814cc08513fcff9d-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a2c2e019a3e54f6f814cc08513fcff9d-0-5\" stroke-width=\"2px\" d=\"M595,264.5 C595,2.0 1100.0,2.0 1100.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a2c2e019a3e54f6f814cc08513fcff9d-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,266.5 L1108.0,254.5 1092.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(docp, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word vector representation\n",
    "Es una representacion numerica  de una palabra que contiene relaciones con otras palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96,)\n",
      "[-0.09407231 -0.9075469  -0.45445594 -1.1411858  -0.44099     0.9385797\n",
      "  1.3443414   0.6658818  -0.5947174   0.5939405   0.07600813  0.72629815\n",
      " -1.106578   -1.3864602  -0.42618632 -0.02737986 -0.10878552  0.71915543\n",
      "  1.1169592   1.2316732  -0.69583136 -0.32771385  1.3548603   1.3309181\n",
      " -0.22622412  1.0586677   0.55602443  0.27411783 -0.17048214  1.2525873\n",
      "  0.2702457  -0.46963167 -2.4193504  -0.60992193  0.38862514  0.6872649\n",
      "  1.1327479   0.35229194 -1.3421861   0.42735565 -0.16393733  1.6086477\n",
      "  0.61497545  1.7041671  -1.0263338  -0.30049253 -0.33176586 -0.34872532\n",
      " -0.8683674  -0.7239049   0.02091672 -1.2001013  -0.7405391  -0.16871308\n",
      "  0.27054113 -1.1542869   0.388623    0.53662574 -1.1061631   0.22368787\n",
      " -0.6537074  -0.17217955  0.55725366 -0.00785073 -0.4597652   0.5792406\n",
      "  0.37737897  0.3109109  -1.0048231   0.23630111  0.34488347 -0.88607776\n",
      "  0.03269416  0.37645274  0.7382326   1.6214384   0.5343185  -0.16599362\n",
      " -0.06891172 -0.9138428   0.0607979  -0.56894875 -0.9574649   0.31991202\n",
      "  0.7803652  -0.41960904  0.9662008  -1.0098635   0.16324358  0.48321325\n",
      " -0.4986184   0.42310557  0.79462427  0.34676063 -0.68169487  0.047521  ]\n"
     ]
    }
   ],
   "source": [
    "comment = pos(text)\n",
    "print(comment.vector.shape)\n",
    "print(comment.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working and scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    print(\"{:-<40} {}\".format(sentence, str(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry for your personal problems however it is your responsible to keep your backers informed. an email once in a while would work.\n",
      "I would like to have your address, phone number and email address.\n",
      "by your actions and keeping your backers in the dark for a year and half I had no other choice but to feel that us backers had been scammed. I personally feel its been long enough already.\n",
      "so if this going to take another year? keep your backers in the loop. Taking our money and never hearing from you is a very asshole thing to do. welcome to the grown world. {'neg': 0.043, 'neu': 0.877, 'pos': 0.08, 'compound': 0.6059}\n"
     ]
    }
   ],
   "source": [
    "sentiment_analyzer_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am sorry for your personal problems however it is your responsible to keep your backers informed.', 'an email once in a while would work.', '\\nI would like to have your address, phone number and email address.', '\\nby your actions and keeping your backers in the dark for a year and half I had no other choice but to feel that us backers had been scammed.', 'I personally feel its been long enough already.', '\\nso if this going to take another year?', 'keep your backers in the loop.', 'Taking our money and never hearing from you is a very asshole thing to do.', 'welcome to the grown world.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry for your personal problems however it is your responsible to keep your backers informed. {'neg': 0.207, 'neu': 0.674, 'pos': 0.119, 'compound': -0.1779}\n",
      "\n",
      "an email once in a while would work.---- {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "\n",
      "I would like to have your address, phone number and email address. {'neg': 0.0, 'neu': 0.703, 'pos': 0.297, 'compound': 0.4215}\n",
      "\n",
      "\n",
      "by your actions and keeping your backers in the dark for a year and half I had no other choice but to feel that us backers had been scammed. {'neg': 0.058, 'neu': 0.942, 'pos': 0.0, 'compound': -0.1531}\n",
      "\n",
      "I personally feel its been long enough already. {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "\n",
      "so if this going to take another year?- {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "keep your backers in the loop.---------- {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "Taking our money and never hearing from you is a very asshole thing to do. {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "welcome to the grown world.------------- {'neg': 0.0, 'neu': 0.571, 'pos': 0.429, 'compound': 0.4588}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in sentences:\n",
    "    sentiment_analyzer_scores(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer_scores(sentence):\n",
    "    ss = analyser.polarity_scores(sentence)\n",
    "    if ss[\"compound\"] >= 0.5:\n",
    "        return \"positive\"\n",
    "    elif ss[\"compound\"] <= -0.5:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms['sentiment'] = cms['comment'].apply(sentiment_analyzer_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am sorry for your personal problems however ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ron, as I told you before, this book publishin...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ron, I really don't appreciate you calling me ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If anyone can help me find Dorian please conta...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dorian, I am going to track you down and expos...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment sentiment\n",
       "0  I am sorry for your personal problems however ...  positive\n",
       "1  Ron, as I told you before, this book publishin...  negative\n",
       "2  Ron, I really don't appreciate you calling me ...  negative\n",
       "3  If anyone can help me find Dorian please conta...  positive\n",
       "4  Dorian, I am going to track you down and expos...   neutral"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cms.drop(['created_at'], 1,inplace=True)\n",
    "cms.drop(['score'], 1, inplace = True)\n",
    "cms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry for your personal problems however it is your responsible to keep your backers informed. an email once in a while would work.\n",
      "I would like to have your address, phone number and email address.\n",
      "by your actions and keeping your backers in the dark for a year and half I had no other choice but to feel that us backers had been scammed. I personally feel its been long enough already.\n",
      "so if this going to take another year? keep your backers in the loop. Taking our money and never hearing from you is a very asshole thing to do. welcome to the grown world.\n"
     ]
    }
   ],
   "source": [
    "print(cms['comment'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ron, as I told you before, this book publishing is proving harder than I previously expected.  This past year and a half has been very hard on me.  I relocated to take care of my grandfather who was battling cancer and passed away.  I have been very depressed and struggling for awhile now.  I cared for my Nana for the last three years of her life and loved her very much.  I'm embarrassed and sad that the book is not published yet.  This is my first book and I'm unsure of the whole process.  How many books have you published?  I never intended to \"scam\" people out of money.  You calling me a \"crook\" is a very asshole thing to do.  I'm sorry you feel that way.\n"
     ]
    }
   ],
   "source": [
    "print(cms['comment'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
